{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DFMDash","text":"<p>Repository for Covid-19 Dynamic Factor Model</p>"},{"location":"cli/","title":"CLI","text":"<p>Command-Line Interface for project</p> <p>Main command     - <code>c19_dfm</code></p> <p>Help     - <code>c19_dfm --help</code></p> <p>Process data and generate parquet DataFrame     - <code>c19_dfm process ./outfile.xlsx</code></p>"},{"location":"cli/#dfmdash.cli.create_input_h5ad","title":"<code>create_input_h5ad(h5ad_out, data_path, factor_path, metadata_path=typer.Option(help='Path to metadata (needed if batching data)'))</code>","text":"<p>Convert data, factor, and metadata CSVs to H5AD and save output</p> <p>Example: c19dfm create_input_h5ad data.h5ad ./data.csv ./factors.csv --metadata ./metadata.csv</p> Source code in <code>dfmdash/cli.py</code> <pre><code>@app.command(\"create_input_data\")\ndef create_input_h5ad(\n    h5ad_out: Path,\n    data_path: Path,\n    factor_path: Path,\n    metadata_path: Optional[Path] = typer.Option(help=\"Path to metadata (needed if batching data)\"),\n):\n    \"\"\"\n    Convert data, factor, and metadata CSVs to H5AD and save output\n\n    Example: c19dfm create_input_h5ad data.h5ad ./data.csv ./factors.csv --metadata ./metadata.csv\n    \"\"\"\n    print(f\"Creating H5AD at {h5ad_out}\")\n    data = DataLoader().load(data_path, factor_path, metadata_path)\n    data.write_h5ad(h5ad_out)\n</code></pre>"},{"location":"cli/#dfmdash.cli.create_project_data","title":"<code>create_project_data(outdir)</code>","text":"<p>Create H5AD object of covid19 response and economic data</p> Source code in <code>dfmdash/cli.py</code> <pre><code>@app.command(\"create_covid_project_data\")\ndef create_project_data(outdir: Path):\n    \"\"\"\n    Create H5AD object of covid19 response and economic data\n    \"\"\"\n    ad = get_project_h5ad()\n    ad.write(outdir / \"data.h5ad\")\n    print(f\"Project data successfully created at {outdir}/data.h5ad !\")\n</code></pre>"},{"location":"cli/#dfmdash.cli.launch","title":"<code>launch(port=8501)</code>","text":"<p>Launch Dynamic Factor Dashboard</p> Source code in <code>dfmdash/cli.py</code> <pre><code>@app.command(\"launch\")\ndef launch(port: str = 8501):\n    \"\"\"\n    Launch Dynamic Factor Dashboard\n    \"\"\"\n    current_dir = Path(__file__).resolve().parent\n    dashboard_path = current_dir / \"streamlit\" / \"Dynamic_Factor_Model.py\"\n    subprocess.run([\"streamlit\", \"run\", dashboard_path, \"--server.port\", port])\n</code></pre>"},{"location":"dfm/","title":"Dynamic Factor Model","text":"<p>Module for Dynamic Factor <code>ModelRunner</code></p>"},{"location":"dfm/#dfmdash.dfm.ModelRunner","title":"<code>ModelRunner</code>","text":"<p>A class for running dynamic factor models on batches of data.</p> <p>Parameters: - ad (AnnData): The AnnData object containing the data. - outdir (Path, optional): The output directory for saving the results. Defaults to \"./output\". - batch (str, optional): The batch column in the AnnData object. Defaults to None.</p> <p>Attributes: - ad (AnnData): The AnnData object containing the data. - outdir (Path): The output directory for saving the results. - batch (str): The batch column in the AnnData object. - batches (dict[str, AnnData]): A dictionary of batches extracted from the AnnData object. - results (list): A list to store the results of each model run. - failures (dict): A dictionary to store any failures that occur during model runs.</p> Source code in <code>dfmdash/dfm.py</code> <pre><code>class ModelRunner:\n    \"\"\"\n    A class for running dynamic factor models on batches of data.\n\n    Parameters:\n    - ad (AnnData): The AnnData object containing the data.\n    - outdir (Path, optional): The output directory for saving the results. Defaults to \"./output\".\n    - batch (str, optional): The batch column in the AnnData object. Defaults to None.\n\n    Attributes:\n    - ad (AnnData): The AnnData object containing the data.\n    - outdir (Path): The output directory for saving the results.\n    - batch (str): The batch column in the AnnData object.\n    - batches (dict[str, AnnData]): A dictionary of batches extracted from the AnnData object.\n    - results (list): A list to store the results of each model run.\n    - failures (dict): A dictionary to store any failures that occur during model runs.\n    \"\"\"\n\n    def __init__(self, ad: AnnData, outdir: Path = Path(\"./output\"), batch: Optional[str] = None):\n        self.ad = ad\n        self.outdir = outdir\n        self.batch = batch\n        self.batches: dict[str, AnnData] = self.get_batches()\n        self.results = []\n        self.failures = {}\n\n    def __repr__(self):\n        return f\"ModelRunner(ad={self.ad}, outdir={self.outdir}, batch={self.batch})\"\n\n    def run(self, maxiter=10_000, global_multiplier=1, columns: Optional[list[str]] = None) -&gt; \"ModelRunner\":\n        \"\"\"\n        Run the dynamic factor models on the batches of data.\n\n        Parameters:\n        - maxiter (int, optional): The maximum number of iterations for model fitting. Defaults to 10,000.\n        - global_multiplier (int, optional): A global multiplier for the model. Defaults to 1.\n        - columns (list[str], optional): The columns to include in the model. Defaults to None.\n\n        Returns:\n        - ModelRunner: The ModelRunner object.\n\n        Raises:\n        - Exception: If an error occurs during model fitting.\n        \"\"\"\n        self.outdir.mkdir(exist_ok=True)\n        print(f\"{len(self.batches)} batches to run\")\n        for batch_name, batch in track(list(self.batches.items())):\n            data = DataProcessor(batch, global_multiplier, maxiter).process(columns)\n            data.write(self.outdir / batch_name) if batch_name else data.write(self.outdir)\n            model = sm.tsa.DynamicFactorMQ(data.df, factors=data.factors, factor_multiplicities=data.multiplicities)\n            try:\n                res = model.fit(disp=10, maxiter=data.maxiter)\n            except Exception as e:\n                print(f\"[bold red]FAILURE[/]{e}\")\n                self.failures[batch_name] = e\n                continue\n            filtered_factors = process_factors(res.factors[\"filtered\"], data.raw, batch.obs)\n            result = Result(batch_name, res, model, filtered_factors)\n            result.write(self.outdir)\n            # self.ad.uns[\"factors\"] = result.factors.drop(columns=\"Time\")\n            # TODO: Fix this. Tests need this present but the dashboard doesn't\n            try:\n                self.ad.obs = self.ad.obs.drop(columns=\"Time\")\n                self.ad.write(self.outdir / batch_name / \"data.h5ad\")\n            except:\n                pass\n            self.results.append(result)\n        # TODO: Concat factors across batch variables\n        print(\"All runs completed!\")\n        return self\n\n    def write_failures(self):\n        \"\"\"\n        Write the failures to a file.\n\n        The failures are written to a file named \"failed.txt\" in the output directory.\n        Each line in the file contains the batch name and the corresponding failure message.\n        \"\"\"\n        for name, failure in self.failures.items():\n            with open(self.outdir / \"failed.txt\", \"a\") as f:\n                f.write(f\"{name}\\t{failure}\\n\")\n\n    def get_batches(self) -&gt; dict[str, AnnData]:\n        \"\"\"\n        Get batches from AnnData object.\n\n        Returns:\n        - dict[str, AnnData]: A dictionary of batches extracted from the AnnData object.\n        \"\"\"\n        if not self.batch:\n            return {None: self.ad}  # Didn't know you could use None as a key, cool\n        return {x: self.ad[self.ad.obs[self.batch] == x] for x in self.ad.obs[self.batch].unique()}\n</code></pre>"},{"location":"dfm/#dfmdash.dfm.ModelRunner.get_batches","title":"<code>get_batches()</code>","text":"<p>Get batches from AnnData object.</p> <p>Returns: - dict[str, AnnData]: A dictionary of batches extracted from the AnnData object.</p> Source code in <code>dfmdash/dfm.py</code> <pre><code>def get_batches(self) -&gt; dict[str, AnnData]:\n    \"\"\"\n    Get batches from AnnData object.\n\n    Returns:\n    - dict[str, AnnData]: A dictionary of batches extracted from the AnnData object.\n    \"\"\"\n    if not self.batch:\n        return {None: self.ad}  # Didn't know you could use None as a key, cool\n    return {x: self.ad[self.ad.obs[self.batch] == x] for x in self.ad.obs[self.batch].unique()}\n</code></pre>"},{"location":"dfm/#dfmdash.dfm.ModelRunner.run","title":"<code>run(maxiter=10000, global_multiplier=1, columns=None)</code>","text":"<p>Run the dynamic factor models on the batches of data.</p> <p>Parameters: - maxiter (int, optional): The maximum number of iterations for model fitting. Defaults to 10,000. - global_multiplier (int, optional): A global multiplier for the model. Defaults to 1. - columns (list[str], optional): The columns to include in the model. Defaults to None.</p> <p>Returns: - ModelRunner: The ModelRunner object.</p> <p>Raises: - Exception: If an error occurs during model fitting.</p> Source code in <code>dfmdash/dfm.py</code> <pre><code>def run(self, maxiter=10_000, global_multiplier=1, columns: Optional[list[str]] = None) -&gt; \"ModelRunner\":\n    \"\"\"\n    Run the dynamic factor models on the batches of data.\n\n    Parameters:\n    - maxiter (int, optional): The maximum number of iterations for model fitting. Defaults to 10,000.\n    - global_multiplier (int, optional): A global multiplier for the model. Defaults to 1.\n    - columns (list[str], optional): The columns to include in the model. Defaults to None.\n\n    Returns:\n    - ModelRunner: The ModelRunner object.\n\n    Raises:\n    - Exception: If an error occurs during model fitting.\n    \"\"\"\n    self.outdir.mkdir(exist_ok=True)\n    print(f\"{len(self.batches)} batches to run\")\n    for batch_name, batch in track(list(self.batches.items())):\n        data = DataProcessor(batch, global_multiplier, maxiter).process(columns)\n        data.write(self.outdir / batch_name) if batch_name else data.write(self.outdir)\n        model = sm.tsa.DynamicFactorMQ(data.df, factors=data.factors, factor_multiplicities=data.multiplicities)\n        try:\n            res = model.fit(disp=10, maxiter=data.maxiter)\n        except Exception as e:\n            print(f\"[bold red]FAILURE[/]{e}\")\n            self.failures[batch_name] = e\n            continue\n        filtered_factors = process_factors(res.factors[\"filtered\"], data.raw, batch.obs)\n        result = Result(batch_name, res, model, filtered_factors)\n        result.write(self.outdir)\n        # self.ad.uns[\"factors\"] = result.factors.drop(columns=\"Time\")\n        # TODO: Fix this. Tests need this present but the dashboard doesn't\n        try:\n            self.ad.obs = self.ad.obs.drop(columns=\"Time\")\n            self.ad.write(self.outdir / batch_name / \"data.h5ad\")\n        except:\n            pass\n        self.results.append(result)\n    # TODO: Concat factors across batch variables\n    print(\"All runs completed!\")\n    return self\n</code></pre>"},{"location":"dfm/#dfmdash.dfm.ModelRunner.write_failures","title":"<code>write_failures()</code>","text":"<p>Write the failures to a file.</p> <p>The failures are written to a file named \"failed.txt\" in the output directory. Each line in the file contains the batch name and the corresponding failure message.</p> Source code in <code>dfmdash/dfm.py</code> <pre><code>def write_failures(self):\n    \"\"\"\n    Write the failures to a file.\n\n    The failures are written to a file named \"failed.txt\" in the output directory.\n    Each line in the file contains the batch name and the corresponding failure message.\n    \"\"\"\n    for name, failure in self.failures.items():\n        with open(self.outdir / \"failed.txt\", \"a\") as f:\n            f.write(f\"{name}\\t{failure}\\n\")\n</code></pre>"},{"location":"dfm/#dfmdash.dfm.Result","title":"<code>Result</code>  <code>dataclass</code>","text":"<p>Represents the result of a dynamic factor model analysis.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Optional[str]</code> <p>Name of the batch if batch is specified.</p> <code>result</code> <code>DynamicFactor</code> <p>The dynamic factor model result.</p> <code>model</code> <code>DynamicFactorMQ</code> <p>The dynamic factor model.</p> <code>factors</code> <code>DataFrame</code> <p>The factors obtained from the analysis.</p> Source code in <code>dfmdash/dfm.py</code> <pre><code>@dataclass\nclass Result:\n    \"\"\"\n    Represents the result of a dynamic factor model analysis.\n\n    Attributes:\n        name (Optional[str]): Name of the batch if batch is specified.\n        result (sm.tsa.DynamicFactor): The dynamic factor model result.\n        model (sm.tsa.DynamicFactorMQ): The dynamic factor model.\n        factors (pd.DataFrame): The factors obtained from the analysis.\n    \"\"\"\n\n    name: Optional[str]\n    result: sm.tsa.DynamicFactor\n    model: sm.tsa.DynamicFactorMQ\n    factors: pd.DataFrame\n\n    def write(self, outdir: Path):\n        \"\"\"\n        Writes the model summary, result summary, and factors to CSV files.\n\n        Args:\n            outdir (Path): The output directory where the files will be written.\n        \"\"\"\n        out = outdir / self.name if self.name else outdir\n        with open(out / \"model.csv\", \"w\") as f:\n            f.write(self.model.summary().as_csv())\n        with open(out / \"results.csv\", \"w\") as f:\n            f.write(self.result.summary().as_csv())\n        self.factors.to_csv(out / \"factors.csv\")\n</code></pre>"},{"location":"dfm/#dfmdash.dfm.Result.write","title":"<code>write(outdir)</code>","text":"<p>Writes the model summary, result summary, and factors to CSV files.</p> <p>Parameters:</p> Name Type Description Default <code>outdir</code> <code>Path</code> <p>The output directory where the files will be written.</p> required Source code in <code>dfmdash/dfm.py</code> <pre><code>def write(self, outdir: Path):\n    \"\"\"\n    Writes the model summary, result summary, and factors to CSV files.\n\n    Args:\n        outdir (Path): The output directory where the files will be written.\n    \"\"\"\n    out = outdir / self.name if self.name else outdir\n    with open(out / \"model.csv\", \"w\") as f:\n        f.write(self.model.summary().as_csv())\n    with open(out / \"results.csv\", \"w\") as f:\n        f.write(self.result.summary().as_csv())\n    self.factors.to_csv(out / \"factors.csv\")\n</code></pre>"},{"location":"dfm/#dfmdash.dfm.process_factors","title":"<code>process_factors(factors, raw, obs)</code>","text":"<p>Process factors by merging them with raw and obs dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>factors</code> <code>DataFrame</code> <p>The factors dataframe.</p> required <code>raw</code> <code>DataFrame</code> <p>The raw dataframe.</p> required <code>obs</code> <code>DataFrame</code> <p>The obs dataframe.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The merged factors dataframe.</p> Source code in <code>dfmdash/dfm.py</code> <pre><code>def process_factors(factors: pd.DataFrame, raw: pd.DataFrame, obs: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Process factors by merging them with raw and obs dataframes.\n\n    Args:\n        factors (pd.DataFrame): The factors dataframe.\n        raw (pd.DataFrame): The raw dataframe.\n        obs (pd.DataFrame): The obs dataframe.\n\n    Returns:\n        pd.DataFrame: The merged factors dataframe.\n    \"\"\"\n    factors.index = raw.index\n    factors = factors.merge(raw, left_index=True, right_index=True)\n    factors.columns = [f\"Factor_{x}\" for x in factors.columns]\n    if not obs.empty:\n        factors = factors.merge(obs, left_index=True, right_index=True)\n    return factors\n</code></pre>"},{"location":"io/","title":"Data Loading","text":"<p>IO module containing <code>DataLoader</code> for interop between DataFrames/CSVs and AnnData H5AD</p>"},{"location":"io/#dfmdash.io.DataLoader","title":"<code>DataLoader</code>  <code>dataclass</code>","text":"<p>A class for loading and manipulating data for the DFMDash project.</p> <p>Attributes:</p> Name Type Description <code>ad</code> <code>Optional[AnnData]</code> <p>An optional AnnData object representing the loaded data.</p> <code>data</code> <code>Optional[DataFrame]</code> <p>An optional pandas DataFrame representing the data.</p> <code>var</code> <code>Optional[DataFrame]</code> <p>An optional pandas DataFrame representing the factors.</p> <code>obs</code> <code>Optional[DataFrame]</code> <p>An optional pandas DataFrame representing the metadata.</p> <p>Methods:</p> Name Description <code>load</code> <p>Path, factors: Path, metadata: Optional[Path] = None) -&gt; DataLoader: Loads the data, factors, and metadata from the specified paths and returns the DataLoader object.</p> <code>convert</code> <p>AnnData) -&gt; DataLoader: Converts the provided AnnData object to DataLoader format and returns the DataLoader object.</p> <code>dfs_to_ad</code> <p>pd.DataFrame, factors: pd.DataFrame, metadata: Optional[pd.DataFrame]) -&gt; AnnData: Converts the provided pandas DataFrames to an AnnData object and returns it.</p> <code>write_csvs</code> <p>Path) -&gt; DataLoader: Writes the data, factors, and metadata to CSV files in the specified output directory and returns the DataLoader object.</p> <code>write_h5ad</code> <p>Path) -&gt; DataLoader: Writes the AnnData object to an H5AD file in the specified output directory and returns the DataLoader object.</p> Source code in <code>dfmdash/io.py</code> <pre><code>@dataclass\nclass DataLoader:\n    \"\"\"\n    A class for loading and manipulating data for the DFMDash project.\n\n    Attributes:\n        ad (Optional[AnnData]): An optional AnnData object representing the loaded data.\n        data (Optional[pd.DataFrame]): An optional pandas DataFrame representing the data.\n        var (Optional[pd.DataFrame]): An optional pandas DataFrame representing the factors.\n        obs (Optional[pd.DataFrame]): An optional pandas DataFrame representing the metadata.\n\n    Methods:\n        load(data: Path, factors: Path, metadata: Optional[Path] = None) -&gt; DataLoader:\n            Loads the data, factors, and metadata from the specified paths and returns the DataLoader object.\n        convert(ad: AnnData) -&gt; DataLoader:\n            Converts the provided AnnData object to DataLoader format and returns the DataLoader object.\n        dfs_to_ad(data: pd.DataFrame, factors: pd.DataFrame, metadata: Optional[pd.DataFrame]) -&gt; AnnData:\n            Converts the provided pandas DataFrames to an AnnData object and returns it.\n        write_csvs(outdir: Path) -&gt; DataLoader:\n            Writes the data, factors, and metadata to CSV files in the specified output directory and returns the DataLoader object.\n        write_h5ad(outdir: Path) -&gt; DataLoader:\n            Writes the AnnData object to an H5AD file in the specified output directory and returns the DataLoader object.\n    \"\"\"\n\n    ad: Optional[AnnData] = None\n    data: Optional[pd.DataFrame] = None\n    var: Optional[pd.DataFrame] = None\n    obs: Optional[pd.DataFrame] = None\n\n    def load(self, data: Path, factors: Path, metadata: Optional[Path] = None) -&gt; \"DataLoader\":\n        self.data = pd.read_csv(data)\n        self.var = pd.read_csv(factors, index_col=0)\n        self.obs = pd.read_csv(metadata, index_col=0) if metadata else None\n        self.ad = self.dfs_to_ad(self.data, self.var, self.obs)\n        return self\n\n    def convert(self, ad: AnnData) -&gt; \"DataLoader\":\n        self.ad = ad\n        self.data = ad.to_df()\n        self.var = ad.var\n        self.obs = ad.obs\n        return self\n\n    def dfs_to_ad(self, data: pd.DataFrame, factors: pd.DataFrame, metadata: Optional[pd.DataFrame]) -&gt; AnnData:\n        data = data[factors.index]  # Force dataframe to be in same order as factor input\n        return AnnData(X=data, obs=metadata, var=factors)\n\n    def write_csvs(self, outdir: Path) -&gt; \"DataLoader\":\n        outdir.mkdir(exist_ok=True)\n        self.data.to_csv(outdir / \"data.csv\")\n        self.var.to_csv(outdir / \"factors.csv\")\n        self.obs.to_csv(outdir / \"metadata.csv\")\n        return self\n\n    def write_h5ad(self, outdir: Path) -&gt; \"DataLoader\":\n        outdir.mkdir(exist_ok=True)\n        self.ad.write(outdir / \"data.h5ad\")\n        return self\n</code></pre>"},{"location":"processing/","title":"Data Processing","text":"<p>Processing module - stores all inputs to run Dynamic Factor Model.</p>"},{"location":"processing/#dfmdash.processing.DataProcessor","title":"<code>DataProcessor</code>","text":"Source code in <code>dfmdash/processing.py</code> <pre><code>class DataProcessor:\n    def __init__(self, ad: AnnData, global_multiplier: int = 1, maxiter: int = 10_000):\n        \"\"\"Prepares inputs for running model\n\n        Args:\n            ad (AnnData): Annotated data object\n            global_multiplier (int, optional): Global multiplier. Defaults to 1.\n            maxiter (int, optional): Maximum number of iterations. Defaults to 10_000.\n        \"\"\"\n        self.ad = ad\n        self.global_multiplier = global_multiplier\n        self.multiplicities = {\"Global\": global_multiplier}\n        self.maxiter = maxiter\n        self.non_stationary_cols = None\n        self.raw: pd.DataFrame = None\n        self.df: pd.DataFrame = None\n\n    def __repr__(self):\n        return f\"DataProcessor(ad={self.ad}, global_multiplier={self.global_multiplier}, maxiter={self.maxiter})\"\n\n    def process(self, columns: Optional[list[str]] = None) -&gt; \"DataProcessor\":\n        \"\"\"Processes the data for the Dynamic Factor Model\n\n        Args:\n            columns (Optional[list[str]], optional): Subset of columns to use. Defaults to None, which uses all columns.\n\n        Returns:\n            DataProcessor: Stores processed data\n        \"\"\"\n        filtered_columns = [x for x in columns if x in columns] if columns else None\n        if filtered_columns and len(filtered_columns) != len(columns):\n            print(f\"Invalid columns removed!\\nInput: {columns}\\nFiltered: {filtered_columns}\")\n        self.raw = self.ad.to_df()[columns] if columns else self.ad.to_df()\n        self.df = self.raw.copy()\n        self.process_differences().drop_constant_cols().normalize()\n        self.factors = {k: v for k, v in self.get_factors().items() if k in self.df.columns}\n        self.stationary_columns = self.get_nonstationary_columns()\n\n        return self\n\n    def write(self, outdir: Path):\n        \"\"\"Writes the processed input data and run info to outdir\n\n        Args:\n            outdir (Path): Output directory\n        \"\"\"\n        outdir.mkdir(exist_ok=True)\n        self.raw.to_csv(outdir / \"raw.csv\")\n        self.df.to_csv(outdir / \"df.csv\")\n        with open(outdir / \"run-info.yaml\", \"w\") as f:\n            yaml.dump(\n                {\n                    \"factor_map\": self.factors,\n                    \"global_multiplier\": self.global_multiplier,\n                    \"maxiter\": self.maxiter,\n                    \"non_stationary_cols\": self.non_stationary_cols,\n                    \"diff_cols\": self.diff_cols,\n                    \"logdiff_cols\": self.logdiff_cols,\n                },\n                f,\n            )\n\n    def get_factors(self) -&gt; dict[str, tuple[str]]:\n        \"\"\"Gets the factor dictionary from the AnnData object for the DFM\n\n        Returns:\n            dict[str, tuple[str]]: Dictionary of factors\n        \"\"\"\n        if \"factor\" not in self.ad.var.columns:\n            msg = \"No `factor` column in AnnData input. Please add to `.var`\"\n            raise RuntimeError(msg)\n        factors = self.ad.var.factor.to_dict()\n        if self.global_multiplier == 0:\n            return {k: (v,) for k, v in factors.items()}\n        return {k: (\"Global\", v) for k, v in factors.items()}\n\n    def process_differences(self) -&gt; \"DataProcessor\":\n        \"\"\"Processes the differences in the data\n\n        Returns:\n            DataProcessor: Processed data\n        \"\"\"\n        self.diff_cols = self.get_diff_cols()\n        self.logdiff_cols = self.get_logdiff_cols()\n        if self.diff_cols:\n            self.diff_vars()\n        if self.logdiff_cols:\n            self.logdiff_vars()\n        if self.diff_cols or self.logdiff_cols:\n            self.df = self.df.iloc[1:]\n            self.raw = self.raw.iloc[1:]  # Trim raw dataframe for parity\n        self.df = self.df.fillna(0)\n        return self\n\n    def drop_constant_cols(self) -&gt; \"DataProcessor\":\n        \"\"\"Drops constant columns from the DataFrame.\n\n        Returns:\n            DataProcessor: Processed data\n        \"\"\"\n        self.df = self.df.loc[:, self.df.columns[~self.df.apply(is_constant)]]\n        return self\n\n    def get_diff_cols(self) -&gt; list[str]:\n        \"\"\"Returns the columns that should be differenced.\n\n        Returns:\n            list[str]: List of columns to be differenced\n        \"\"\"\n        return self._get_cols(\"difference\")\n\n    def get_logdiff_cols(self) -&gt; list[str]:\n        \"\"\"Returns the columns that should be log-differenced.\n\n        Returns:\n            list[str]: List of columns to be log-differenced\n        \"\"\"\n        return self._get_cols(\"logdiff\")\n\n    def _get_cols(self, colname: str) -&gt; list[str]:\n        \"\"\"Helper function to get columns based on a specific condition\n\n        Args:\n            colname (str): Name of the condition\n\n        Returns:\n            list[str]: List of columns that satisfy the condition\n        \"\"\"\n        if colname not in self.ad.var.columns:\n            return []\n        columns = self.ad.var.query(f\"{colname} == True\").index.to_list()\n        return [x for x in columns if x in self.df.columns]\n\n    def diff_vars(self) -&gt; \"DataProcessor\":\n        \"\"\"Performs differencing on the specified columns\n\n        Returns:\n            DataProcessor: Processed data\n        \"\"\"\n        self.df[self.diff_cols] = self.df[self.diff_cols].diff()\n        return self\n\n    def logdiff_vars(self) -&gt; \"DataProcessor\":\n        \"\"\"Performs log-differencing on the specified columns\n\n        Returns:\n            DataProcessor: Processed data\n        \"\"\"\n        self.df[self.logdiff_cols] = self.df[self.logdiff_cols].apply(lambda x: np.log(x + 1)).diff()\n        return self\n\n    def get_nonstationary_columns(self) -&gt; list[str]:\n        \"\"\"Runs AD-Fuller test on columns and returns non-stationary columns\n\n        Returns:\n            list[str]: List of non-stationary columns\n        \"\"\"\n        cols = []\n        for col in self.df.columns:\n            result = adfuller(self.df[col])\n            p_value = result[1]\n            if p_value &gt; 0.25:  # TODO: Ask Aaron/Josh - p-value 0.25 is pretty weird\n                cols.append(col)\n        print(f\"Columns that fail the ADF test (non-stationary)\\n{cols}\")\n        return cols\n\n    def normalize(self) -&gt; \"DataProcessor\":\n        \"\"\"Normalizes the data between 0 and 1\n\n        Returns:\n            DataProcessor: Processed data\n        \"\"\"\n        self.df = pd.DataFrame(MinMaxScaler().fit_transform(self.df), columns=self.df.columns)\n        self.df.index = self.raw.index\n        return self\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.__init__","title":"<code>__init__(ad, global_multiplier=1, maxiter=10000)</code>","text":"<p>Prepares inputs for running model</p> <p>Parameters:</p> Name Type Description Default <code>ad</code> <code>AnnData</code> <p>Annotated data object</p> required <code>global_multiplier</code> <code>int</code> <p>Global multiplier. Defaults to 1.</p> <code>1</code> <code>maxiter</code> <code>int</code> <p>Maximum number of iterations. Defaults to 10_000.</p> <code>10000</code> Source code in <code>dfmdash/processing.py</code> <pre><code>def __init__(self, ad: AnnData, global_multiplier: int = 1, maxiter: int = 10_000):\n    \"\"\"Prepares inputs for running model\n\n    Args:\n        ad (AnnData): Annotated data object\n        global_multiplier (int, optional): Global multiplier. Defaults to 1.\n        maxiter (int, optional): Maximum number of iterations. Defaults to 10_000.\n    \"\"\"\n    self.ad = ad\n    self.global_multiplier = global_multiplier\n    self.multiplicities = {\"Global\": global_multiplier}\n    self.maxiter = maxiter\n    self.non_stationary_cols = None\n    self.raw: pd.DataFrame = None\n    self.df: pd.DataFrame = None\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor._get_cols","title":"<code>_get_cols(colname)</code>","text":"<p>Helper function to get columns based on a specific condition</p> <p>Parameters:</p> Name Type Description Default <code>colname</code> <code>str</code> <p>Name of the condition</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of columns that satisfy the condition</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def _get_cols(self, colname: str) -&gt; list[str]:\n    \"\"\"Helper function to get columns based on a specific condition\n\n    Args:\n        colname (str): Name of the condition\n\n    Returns:\n        list[str]: List of columns that satisfy the condition\n    \"\"\"\n    if colname not in self.ad.var.columns:\n        return []\n    columns = self.ad.var.query(f\"{colname} == True\").index.to_list()\n    return [x for x in columns if x in self.df.columns]\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.diff_vars","title":"<code>diff_vars()</code>","text":"<p>Performs differencing on the specified columns</p> <p>Returns:</p> Name Type Description <code>DataProcessor</code> <code>DataProcessor</code> <p>Processed data</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def diff_vars(self) -&gt; \"DataProcessor\":\n    \"\"\"Performs differencing on the specified columns\n\n    Returns:\n        DataProcessor: Processed data\n    \"\"\"\n    self.df[self.diff_cols] = self.df[self.diff_cols].diff()\n    return self\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.drop_constant_cols","title":"<code>drop_constant_cols()</code>","text":"<p>Drops constant columns from the DataFrame.</p> <p>Returns:</p> Name Type Description <code>DataProcessor</code> <code>DataProcessor</code> <p>Processed data</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def drop_constant_cols(self) -&gt; \"DataProcessor\":\n    \"\"\"Drops constant columns from the DataFrame.\n\n    Returns:\n        DataProcessor: Processed data\n    \"\"\"\n    self.df = self.df.loc[:, self.df.columns[~self.df.apply(is_constant)]]\n    return self\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.get_diff_cols","title":"<code>get_diff_cols()</code>","text":"<p>Returns the columns that should be differenced.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of columns to be differenced</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def get_diff_cols(self) -&gt; list[str]:\n    \"\"\"Returns the columns that should be differenced.\n\n    Returns:\n        list[str]: List of columns to be differenced\n    \"\"\"\n    return self._get_cols(\"difference\")\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.get_factors","title":"<code>get_factors()</code>","text":"<p>Gets the factor dictionary from the AnnData object for the DFM</p> <p>Returns:</p> Type Description <code>dict[str, tuple[str]]</code> <p>dict[str, tuple[str]]: Dictionary of factors</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def get_factors(self) -&gt; dict[str, tuple[str]]:\n    \"\"\"Gets the factor dictionary from the AnnData object for the DFM\n\n    Returns:\n        dict[str, tuple[str]]: Dictionary of factors\n    \"\"\"\n    if \"factor\" not in self.ad.var.columns:\n        msg = \"No `factor` column in AnnData input. Please add to `.var`\"\n        raise RuntimeError(msg)\n    factors = self.ad.var.factor.to_dict()\n    if self.global_multiplier == 0:\n        return {k: (v,) for k, v in factors.items()}\n    return {k: (\"Global\", v) for k, v in factors.items()}\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.get_logdiff_cols","title":"<code>get_logdiff_cols()</code>","text":"<p>Returns the columns that should be log-differenced.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of columns to be log-differenced</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def get_logdiff_cols(self) -&gt; list[str]:\n    \"\"\"Returns the columns that should be log-differenced.\n\n    Returns:\n        list[str]: List of columns to be log-differenced\n    \"\"\"\n    return self._get_cols(\"logdiff\")\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.get_nonstationary_columns","title":"<code>get_nonstationary_columns()</code>","text":"<p>Runs AD-Fuller test on columns and returns non-stationary columns</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of non-stationary columns</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def get_nonstationary_columns(self) -&gt; list[str]:\n    \"\"\"Runs AD-Fuller test on columns and returns non-stationary columns\n\n    Returns:\n        list[str]: List of non-stationary columns\n    \"\"\"\n    cols = []\n    for col in self.df.columns:\n        result = adfuller(self.df[col])\n        p_value = result[1]\n        if p_value &gt; 0.25:  # TODO: Ask Aaron/Josh - p-value 0.25 is pretty weird\n            cols.append(col)\n    print(f\"Columns that fail the ADF test (non-stationary)\\n{cols}\")\n    return cols\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.logdiff_vars","title":"<code>logdiff_vars()</code>","text":"<p>Performs log-differencing on the specified columns</p> <p>Returns:</p> Name Type Description <code>DataProcessor</code> <code>DataProcessor</code> <p>Processed data</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def logdiff_vars(self) -&gt; \"DataProcessor\":\n    \"\"\"Performs log-differencing on the specified columns\n\n    Returns:\n        DataProcessor: Processed data\n    \"\"\"\n    self.df[self.logdiff_cols] = self.df[self.logdiff_cols].apply(lambda x: np.log(x + 1)).diff()\n    return self\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.normalize","title":"<code>normalize()</code>","text":"<p>Normalizes the data between 0 and 1</p> <p>Returns:</p> Name Type Description <code>DataProcessor</code> <code>DataProcessor</code> <p>Processed data</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def normalize(self) -&gt; \"DataProcessor\":\n    \"\"\"Normalizes the data between 0 and 1\n\n    Returns:\n        DataProcessor: Processed data\n    \"\"\"\n    self.df = pd.DataFrame(MinMaxScaler().fit_transform(self.df), columns=self.df.columns)\n    self.df.index = self.raw.index\n    return self\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.process","title":"<code>process(columns=None)</code>","text":"<p>Processes the data for the Dynamic Factor Model</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Optional[list[str]]</code> <p>Subset of columns to use. Defaults to None, which uses all columns.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataProcessor</code> <code>DataProcessor</code> <p>Stores processed data</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def process(self, columns: Optional[list[str]] = None) -&gt; \"DataProcessor\":\n    \"\"\"Processes the data for the Dynamic Factor Model\n\n    Args:\n        columns (Optional[list[str]], optional): Subset of columns to use. Defaults to None, which uses all columns.\n\n    Returns:\n        DataProcessor: Stores processed data\n    \"\"\"\n    filtered_columns = [x for x in columns if x in columns] if columns else None\n    if filtered_columns and len(filtered_columns) != len(columns):\n        print(f\"Invalid columns removed!\\nInput: {columns}\\nFiltered: {filtered_columns}\")\n    self.raw = self.ad.to_df()[columns] if columns else self.ad.to_df()\n    self.df = self.raw.copy()\n    self.process_differences().drop_constant_cols().normalize()\n    self.factors = {k: v for k, v in self.get_factors().items() if k in self.df.columns}\n    self.stationary_columns = self.get_nonstationary_columns()\n\n    return self\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.process_differences","title":"<code>process_differences()</code>","text":"<p>Processes the differences in the data</p> <p>Returns:</p> Name Type Description <code>DataProcessor</code> <code>DataProcessor</code> <p>Processed data</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def process_differences(self) -&gt; \"DataProcessor\":\n    \"\"\"Processes the differences in the data\n\n    Returns:\n        DataProcessor: Processed data\n    \"\"\"\n    self.diff_cols = self.get_diff_cols()\n    self.logdiff_cols = self.get_logdiff_cols()\n    if self.diff_cols:\n        self.diff_vars()\n    if self.logdiff_cols:\n        self.logdiff_vars()\n    if self.diff_cols or self.logdiff_cols:\n        self.df = self.df.iloc[1:]\n        self.raw = self.raw.iloc[1:]  # Trim raw dataframe for parity\n    self.df = self.df.fillna(0)\n    return self\n</code></pre>"},{"location":"processing/#dfmdash.processing.DataProcessor.write","title":"<code>write(outdir)</code>","text":"<p>Writes the processed input data and run info to outdir</p> <p>Parameters:</p> Name Type Description Default <code>outdir</code> <code>Path</code> <p>Output directory</p> required Source code in <code>dfmdash/processing.py</code> <pre><code>def write(self, outdir: Path):\n    \"\"\"Writes the processed input data and run info to outdir\n\n    Args:\n        outdir (Path): Output directory\n    \"\"\"\n    outdir.mkdir(exist_ok=True)\n    self.raw.to_csv(outdir / \"raw.csv\")\n    self.df.to_csv(outdir / \"df.csv\")\n    with open(outdir / \"run-info.yaml\", \"w\") as f:\n        yaml.dump(\n            {\n                \"factor_map\": self.factors,\n                \"global_multiplier\": self.global_multiplier,\n                \"maxiter\": self.maxiter,\n                \"non_stationary_cols\": self.non_stationary_cols,\n                \"diff_cols\": self.diff_cols,\n                \"logdiff_cols\": self.logdiff_cols,\n            },\n            f,\n        )\n</code></pre>"},{"location":"processing/#dfmdash.processing.is_constant","title":"<code>is_constant(column)</code>","text":"<p>Returns True if a DataFrame column is constant</p> Source code in <code>dfmdash/processing.py</code> <pre><code>def is_constant(column) -&gt; bool:\n    \"\"\"Returns True if a DataFrame column is constant\"\"\"\n    return all(column == column.iloc[0])\n</code></pre>"}]}